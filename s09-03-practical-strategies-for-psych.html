<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <link href="shared/bookhub.css" rel="stylesheet" type="text/css">
  <title>Practical Strategies for Psychological Measurement</title>
</head>
<body>

  
  <div id=navbar-top class="navbar">
    <div class="navbar-part left">
      
        <a href="s09-02-reliability-and-validity-of-me.html"><img src="shared/images/batch-left.png"></a> <a href="s09-02-reliability-and-validity-of-me.html">Previous Section</a>
      
    </div>
    <div class="navbar-part middle">
      <a href="index.html"><img src="shared/images/batch-up.png"></a> <a href="index.html">Table of Contents</a>
    </div>
    <div class="navbar-part right">
      
        <a href="s10-01-experiment-basics.html">Next Section</a> <a href="s10-01-experiment-basics.html"><img src="shared/images/batch-right.png"></a>
      
    </div>
  </div>

  <div id="book-content">
    <div class="section" id="price_1.0-ch05_s03" condition="start-of-chunk" version="5.0" lang="en">
    <h2 class="title editable block">
<span class="title-prefix">5.3</span> Practical Strategies for Psychological Measurement</h2>
    <div class="learning_objectives editable block" id="price_1.0-ch05_s03_n01">
        <h3 class="title">Learning Objectives</h3>
        <ol class="orderedlist" id="price_1.0-ch05_s03_l01">
            <li>Specify the four broad steps in the measurement process.</li>
            <li>Explain how you would decide whether to use an existing measure or create your own.</li>
            <li>Describe multiple strategies to identify and locate existing measures of psychological constructs.</li>
            <li>Describe several general principles for creating new measures and for implementing existing and new measures.</li>
            <li>Create a simple plan for assessing the reliability and validity of an existing or new measure.</li>
        </ol>
    </div>
    <p class="para editable block" id="price_1.0-ch05_s03_p01">So far in this chapter, we have considered several basic ideas about the nature of psychological constructs and their measurement. But now imagine that you are in the position of actually having to measure a psychological construct for a research project. How should you proceed? Broadly speaking, there are four steps in the measurement process: (a) conceptually defining the construct, (b) operationally defining the construct, (c) implementing the measure, and (d) evaluating the measure. In this section, we will look at each of these steps in turn.</p>
    <div class="section" id="price_1.0-ch05_s03_s01">
        <h2 class="title editable block">Conceptually Defining the Construct</h2>
        <p class="para editable block" id="price_1.0-ch05_s03_s01_p01">Having a clear and complete conceptual definition of a construct is a prerequisite for good measurement. For one thing, it allows you to make sound decisions about exactly how to measure the construct. If you had only a vague idea that you wanted to measure people’s “memory,” for example, you would have no way to choose whether you should have them remember a list of vocabulary words, a set of photographs, a newly learned skill, or an experience from long ago. Because psychologists now conceptualize memory as a set of semi-independent systems, you would have to be more precise about what you mean by “memory.” If you are interested in long-term declarative memory (memory for facts), then having participants remember a list of words that they learned last week would make sense, but having them remember and execute a newly learned skill would not. In general, there is no substitute for reading the research literature on a construct and paying close attention to how others have defined it.</p>
    </div>
    <div class="section" id="price_1.0-ch05_s03_s02">
        <h2 class="title editable block">Deciding on an Operational Definition</h2>
        <div class="section" id="price_1.0-ch05_s03_s02_s01">
            <h2 class="title editable block">Using an Existing Measure</h2>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s01_p01">It is usually a good idea to use an existing measure that has been used successfully in previous research. Among the advantages are that (a) you save the time and trouble of creating your own, (b) there is already some evidence that the measure is valid (if it has been used successfully), and (c) your results can more easily be compared with and combined with previous results. In fact, if there already exists a reliable and valid measure of a construct, other researchers might expect you to use it unless you have a good and clearly stated reason for not doing so.</p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s01_p02">If you choose to use an existing measure, you may still have to choose among several alternatives. You might choose the most common one, the one with the best evidence of reliability and validity, the one that best measures a particular aspect of a construct that you are interested in (e.g., a physiological measure of stress if you are most interested in its underlying physiology), or even the one that would be easiest to use. For example, the Ten-Item Personality Inventory (TIPI) is a self-report questionnaire that measures all the Big Five personality dimensions with just 10 items (Gosling, Rentfrow, &amp; Swann, 2003).<span class="footnote" id="price_1.0-fn05_010">Gosling, S. D., Rentfrow, P. J., &amp; Swann, W. B., Jr. (2003). A very brief measure of the Big Five personality domains. <em class="emphasis">Journal of Research in Personality, 37</em>, 504–528.</span> It is not as reliable or valid as longer and more comprehensive measures, but a researcher might choose to use it when testing time is severely limited.</p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s01_p03">When an existing measure was created primarily for use in scientific research, it is usually described in detail in a published research article and is free to use in your own research—with a proper citation. You might find that later researchers who use the same measure describe it only briefly but provide a reference to the original article, in which case you would have to get the details from the original article. The American Psychological Association also publishes the <em class="emphasis">Directory of Unpublished Experimental Measures</em>, which is an extensive catalog of measures that have been used in previous research. Many existing measures—especially those that have applications in clinical psychology—are proprietary. This means that a publisher owns the rights to them and that you would have to purchase them. These include many standard intelligence tests, the Beck Depression Inventory, and the Minnesota Multiphasic Personality Inventory (MMPI). Details about many of these measures and how to obtain them can be found in other reference books, including <em class="emphasis">Tests in Print</em> and the <em class="emphasis">Mental Measurements Yearbook</em>. There is a good chance you can find these reference books in your college or university library.</p>
        </div>
        <div class="section" id="price_1.0-ch05_s03_s02_s02">
            <h2 class="title editable block">Creating Your Own Measure</h2>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s02_p01">Instead of using an existing measure, you might want to create your own. Perhaps there is no existing measure of the construct you are interested in or existing ones are too difficult or time-consuming to use. Or perhaps you want to use a new measure specifically to see whether it works in the same way as existing measures—that is, to demonstrate converging operations. In this section, we consider some general issues in creating new measures that apply equally to self-report, behavioral, and physiological measures. More detailed guidelines for creating self-report measures are presented in <a class="xref" href="price_1.0-ch09#price_1.0-ch09">Chapter 9 "Survey Research"</a>.</p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s02_p02">First, be aware that most new measures in psychology are really variations of existing measures, so you should still look to the research literature for ideas. Perhaps you can modify an existing questionnaire, create a paper-and-pencil version of a measure that is normally computerized (or vice versa), or adapt a measure that has traditionally been used for another purpose. For example, the famous Stroop task (Stroop, 1935)<span class="footnote" id="price_1.0-fn05_011">Stroop, J. R. (1935). Studies of interference in serial verbal reactions. <em class="emphasis">Journal of Experimental Psychology, 18</em>, 643–662.</span>—in which people quickly name the colors that various color words are printed in—has been adapted for the study of social anxiety. Socially anxious people are slower at color naming when the words have negative social connotations such as “stupid” (Amir, Freshman, &amp; Foa, 2002).<span class="footnote" id="price_1.0-fn05_012">Amir, N., Freshman, M., &amp; Foa, E. (2002). Enhanced Stroop interference for threat in social phobia. <em class="emphasis">Journal of Anxiety Disorders, 16</em>, 1–9.</span></p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s02_p03">When you create a new measure, you should strive for simplicity. Remember that your participants are not as interested in your research as you are and that they will vary widely in their ability to understand and carry out whatever task you give them. You should create a set of clear instructions using simple language that you can present in writing or read aloud (or both). It is also a good idea to include one or more practice items so that participants can become familiar with the task, and to build in an opportunity for them to ask questions before continuing. It is also best to keep the measure brief to avoid boring or frustrating your participants to the point that their responses start to become less reliable and valid.</p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s02_p04">The need for brevity, however, needs to be weighed against the fact that it is nearly always better for a measure to include multiple items rather than a single item. There are two reasons for this. One is a matter of content validity. Multiple items are often required to cover a construct adequately. The other is a matter of reliability. People’s responses to single items can be influenced by all sorts of irrelevant factors—misunderstanding the particular item, a momentary distraction, or a simple error such as checking the wrong response option. But when several responses are summed or averaged, the effects of these irrelevant factors tend to cancel each other out to produce more reliable scores. Remember, however, that multiple items must be structured in a way that allows them to be combined into a single overall score by summing or averaging. To measure “financial responsibility,” a student might ask people about their annual income, obtain their credit score, and have them rate how “thrifty” they are—but there is no obvious way to combine these responses into an overall score. To create a true multiple-item measure, the student might instead ask people to rate the degree to which 10 statements about financial responsibility describe them on the same five-point scale.</p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s02_p05">Finally, the very best way to assure yourself that your measure has clear instructions, includes sufficient practice, and is an appropriate length is to test several people. (Family and friends often serve this purpose nicely). Observe them as they complete the task, time them, and ask them afterward to comment on how easy or difficult it was, whether the instructions were clear, and anything else you might be wondering about. Obviously, it is better to discover problems with a measure before beginning any large-scale data collection.</p>
        </div>
        <div class="section" id="price_1.0-ch05_s03_s02_s03">
            <h2 class="title editable block">Implementing the Measure</h2>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s03_p01">You will want to implement any measure in a way that maximizes its reliability and validity. In most cases, it is best to test everyone under similar conditions that, ideally, are quiet and free of distractions. Testing participants in groups is often done because it is efficient, but be aware that it can create distractions that reduce the reliability and validity of the measure. As always, it is good to use previous research as a guide. If others have successfully tested people in groups using a particular measure, then you should consider doing it too.</p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s03_p02">Be aware also that people can react in a variety of ways to being measured that reduce the reliability and validity of the scores. Although some disagreeable participants might intentionally respond in ways meant to “mess up” a study, participant <span class="margin_term"><a class="glossterm">reactivity</a><span class="glossdef">Participants’ reactions to the fact that they are being measured.</span></span> is more likely to take the opposite form. Agreeable participants might respond in ways they believe they are expected to. They might engage in <span class="margin_term"><a class="glossterm">socially desirable responding</a><span class="glossdef">Participants’ responding in ways they believe to be socially appropriate rather than in ways that reflect their actual thoughts, feelings, and behavior.</span></span>. For example, people with low self-esteem agree that they feel they are a person of worth not because they really feel this way but because they believe this is the socially appropriate response and do not want to look bad in the eyes of the researcher. Additionally, research studies can have built-in <span class="margin_term"><a class="glossterm">demand characteristics</a><span class="glossdef">Features of a study that cue participants as to how the researcher expects them to behave.</span></span>: cues to how the researcher expects participants to behave. For example, a participant whose attitude toward exercise is measured immediately after she is asked to read a passage about the dangers of heart disease might reasonably conclude that the passage was meant to improve her attitude. As a result, she might respond more favorably because she believes she is expected to by the researcher. Finally, your own expectations can bias participants’ behaviors in unintended ways.</p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s03_p03">There are several precautions you can take to minimize these kinds of reactivity. One is to make the procedure as clear and brief as possible so that participants are not tempted to take out their frustrations on your results. Another is to guarantee participants’ anonymity and make clear to them that you are doing so. If you are testing them in groups, be sure that they are seated far enough apart that they cannot see each other’s responses. Give them all the same type of writing implement so that they cannot be identified by, for example, the pink glitter pen that they used. You can even allow them to seal completed questionnaires into individual envelopes or put them into a drop box where they immediately become mixed with others’ questionnaires. Although informed consent requires telling participants what they will be doing, it does not require revealing your hypothesis or other information that might suggest to participants how you expect them to respond. A questionnaire designed to measure financial responsibility need not be titled “Are You Financially Responsible?” It could be titled “Money Questionnaire” or have no title at all. Finally, the effects of your expectations can be minimized by arranging to have the measure administered by a helper who is unaware of its intent or of any hypothesis being tested. Regardless of whether this is possible, you should standardize all interactions between researchers and participants—for example, by always reading the same set of instructions word for word.</p>
        </div>
        <div class="section" id="price_1.0-ch05_s03_s02_s04">
            <h2 class="title editable block">Evaluating the Measure</h2>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s04_p01">Once you have used your measure on a sample of people and have a set of scores, you are in a position to evaluate it more thoroughly in terms of reliability and validity. Even if the measure has been used extensively by other researchers and has already shown evidence of reliability and validity, you should not assume that it worked as expected for your particular sample and under your particular testing conditions. Regardless, you now have additional evidence bearing on the reliability and validity of the measure, and it would make sense to add that evidence to the research literature.</p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s04_p02">In most research designs, it is not possible to assess test-retest reliability because participants are tested at only one time. For a new measure, you might design a study specifically to assess its test-retest reliability by testing the same set of participants at two times. In other cases, a study designed to answer a different question still allows for the assessment of test-retest reliability. For example, a psychology instructor might measure his students’ attitude toward critical thinking using the same measure at the beginning and end of the semester to see if there is any change. Even if there is no change, he could still look at the correlation between students’ scores at the two times to assess the measure’s test-retest reliability. It is also customary to assess internal consistency for any multiple-item measure—usually by looking at a split-half correlation or Cronbach’s alpha.</p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s04_p03">Criterion and discriminant validity can be assessed in various ways. For example, if your study included more than one measure of the same construct or measures of conceptually distinct constructs, then you should look at the correlations among these measures to be sure that they fit your expectations. Note also that a successful experimental manipulation also provides evidence of criterion validity. Recall that MacDonald and Martineau manipulated participant’s moods by having them think either positive or negative thoughts, and after the manipulation their mood measure showed a distinct difference between the two groups. This simultaneously provided evidence that their mood manipulation worked <em class="emphasis">and</em> that their mood measure was valid.</p>
            <p class="para editable block" id="price_1.0-ch05_s03_s02_s04_p04">But what if your newly collected data cast doubt on the reliability or validity of your measure? The short answer is that you have to ask why. It could be that there is something wrong with your measure or how you administered it. It could be that there is something wrong with your conceptual definition. It could be that your experimental manipulation failed. For example, if a mood measure showed no difference between people whom you instructed to think positive versus negative thoughts, maybe it is because the participants did not actually think the thoughts they were supposed to or that the thoughts did not actually affect their moods. In short, it is “back to the drawing board” to revise the measure, revise the conceptual definition, or try a new manipulation.</p>
            <div class="key_takeaways editable block" id="price_1.0-ch05_s03_s02_s04_n01">
                <h3 class="title">Key Takeaways</h3>
                <ul class="itemizedlist" id="price_1.0-ch05_s03_s02_s04_l01">
                    <li>Good measurement begins with a clear conceptual definition of the construct to be measured. This is accomplished both by clear and detailed thinking and by a review of the research literature.</li>
                    <li>You often have the option of using an existing measure or creating a new measure. You should make this decision based on the availability of existing measures and their adequacy for your purposes.</li>
                    <li>Several simple steps can be taken in creating new measures and in implementing both existing and new measures that can help maximize reliability and validity.</li>
                    <li>Once you have used a measure, you should reevaluate its reliability and validity based on your new data. Remember that the assessment of reliability and validity is an ongoing process.</li>
                </ul>
            </div>
            <div class="exercises editable block" id="price_1.0-ch05_s03_s02_s04_n02">
                <h3 class="title">Exercises</h3>
                <ol class="orderedlist" id="price_1.0-ch05_s03_s02_s04_l02">
                    <li>Practice: Write your own conceptual definition of self-confidence, irritability, and athleticism.</li>
                    <li>Practice: Choose a construct (sexual jealousy, self-confidence, etc.) and find two measures of that construct in the research literature. If you were conducting your own study, which one (if either) would you use and why?</li>
                </ol>
            </div>
        </div>
    </div>
</div>

  </div>
  
  <div id=navbar-bottom class="navbar">
    <div class="navbar-part left">
      
        <a href="s09-02-reliability-and-validity-of-me.html"><img src="shared/images/batch-left.png"></a> <a href="s09-02-reliability-and-validity-of-me.html">Previous Section</a>
      
    </div>
    <div class="navbar-part middle">
      <a href="index.html"><img src="shared/images/batch-up.png"></a> <a href="index.html">Table of Contents</a>
    </div>
    <div class="navbar-part right">
      
        <a href="s10-01-experiment-basics.html">Next Section</a> <a href="s10-01-experiment-basics.html"><img src="shared/images/batch-right.png"></a>
      
    </div>
  </div>

  </div>
  <script type="text/javascript" src="shared/book.js"></script>
  
  
</body>
</html>
